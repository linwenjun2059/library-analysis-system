# ğŸ“‹ éƒ¨ç½²ä¸è¿ç»´å®Œæ•´æŒ‡å—

> æœ¬æ–‡æ¡£æ•´åˆäº†æ‰€æœ‰éƒ¨ç½²ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬ç¯å¢ƒå‡†å¤‡ã€æ•°æ®é“¾è·¯æ‰§è¡Œã€é—®é¢˜æ’æŸ¥ç­‰ã€‚

---

## ğŸ“‘ ç›®å½•

- [ä¸€ã€ç¯å¢ƒå‡†å¤‡](#ä¸€ç¯å¢ƒå‡†å¤‡)
- [äºŒã€æ•°æ®é“¾è·¯æ‰§è¡Œ](#äºŒæ•°æ®é“¾è·¯æ‰§è¡Œ)
- [ä¸‰ã€æ­¥éª¤éªŒè¯](#ä¸‰æ­¥éª¤éªŒè¯)
- [å››ã€åç«¯éƒ¨ç½²](#å››åç«¯éƒ¨ç½²)
- [äº”ã€å‰ç«¯éƒ¨ç½²](#äº”å‰ç«¯éƒ¨ç½²)
- [å…­ã€é—®é¢˜æ’æŸ¥](#å…­é—®é¢˜æ’æŸ¥)
- [ä¸ƒã€æ€§èƒ½ä¼˜åŒ–](#ä¸ƒæ€§èƒ½ä¼˜åŒ–)
- [å…«ã€è¿ç»´ç›‘æ§](#å…«è¿ç»´ç›‘æ§)

---

## âš¡ å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

åœ¨æ‰§è¡Œæ•°æ®é“¾è·¯ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

- [ ] **Hadoopé›†ç¾¤æ­£å¸¸è¿è¡Œ**
  ```bash
  hdfs dfsadmin -report
  yarn node -list
  ```

- [ ] **Hive Metastoreå·²å¯åŠ¨**
  ```bash
  jps | grep HiveMetaStore
  hive -e "SHOW DATABASES"
  ```

- [ ] **â­ MySQLè¡¨å·²åˆ›å»ºï¼ˆå¿…é¡»ï¼ï¼‰**
  ```bash
  mysql -uroot -p780122 < ../bigdata/mysql/init_mysql.sql
  mysql -uroot -p780122 library_analysis -e "SHOW TABLES;"
  # é¢„æœŸï¼š29å¼ è¡¨
  ```

- [ ] **CSVæ•°æ®æ–‡ä»¶å·²å‡†å¤‡**
  ```bash
  ls -lh /home/hadoop/LENDHIST2019_2020.csv
  ```

- [ ] **Pythonä¾èµ–å·²å®‰è£…**
  ```bash
  pip3 list | grep -E "pandas|pymysql"
  ```

- [ ] **MySQL JDBCé©±åŠ¨å·²ä¸‹è½½**
  ```bash
  ls -lh /opt/app/spark/jars/mysql-connector-j-8.0.33.jar
  ```

**å®Œæˆä»¥ä¸Šæ£€æŸ¥åï¼Œå³å¯å¼€å§‹æ‰§è¡Œæ•°æ®é“¾è·¯ï¼**

```bash
cd /home/hadoop/library-analysis-system/deploy
bash run.sh
```

---

## ä¸€ã€ç¯å¢ƒå‡†å¤‡

### 1.1 é›†ç¾¤é…ç½®

**æ¨èé…ç½®**ï¼ˆ10ä¸‡æ¡æ•°æ®ï¼‰ï¼š

| èŠ‚ç‚¹ | è§’è‰² | é…ç½® |
|-----|------|------|
| master | NameNode, ResourceManager, Hive Metastore | 8Gå†…å­˜, 4æ ¸CPU |
| slave1 | DataNode, NodeManager | 4Gå†…å­˜, 4æ ¸CPU |
| slave2 | DataNode, NodeManager | 4Gå†…å­˜, 4æ ¸CPU |

### 1.2 è½¯ä»¶ç‰ˆæœ¬

```bash
# å¿…éœ€ç»„ä»¶
Hadoop: 3.3.6
Hive: 3.1.2
Spark: 3.5.6
MySQL: 8.0
JDK: 1.8
Python: 3.6+

# å¯é€‰ç»„ä»¶ï¼ˆå‰åç«¯ï¼‰
Node.js: 16+
Maven: 3.6+
```

### 1.3 å‰ç½®æ£€æŸ¥

```bash
# æ£€æŸ¥Hadoop
hdfs dfsadmin -report
yarn node -list

# æ£€æŸ¥Hive Metastore
jps | grep HiveMetaStore
hive -e "SHOW DATABASES"

# æ£€æŸ¥MySQL
mysql -u root -p780122 -e "SELECT VERSION()"

# æ£€æŸ¥Pythonä¾èµ–
python3 --version
pip3 list | grep -E "pandas|pymysql"
```

### 1.4 åˆå§‹åŒ–MySQLæ•°æ®åº“ â­ å¿…é¡»

**âš ï¸ é‡è¦ï¼šåœ¨æ‰§è¡Œæ•°æ®é“¾è·¯ä¹‹å‰ï¼Œå¿…é¡»å…ˆåˆ›å»ºMySQLè¡¨ï¼**

```bash
# 1. ä¸Šä¼ SQLåˆå§‹åŒ–è„šæœ¬åˆ°masterèŠ‚ç‚¹
scp bigdata/mysql/init_mysql.sql hadoop@master:/home/hadoop/

# 2. SSHç™»å½•masterèŠ‚ç‚¹
ssh hadoop@master

# 3. æ‰§è¡ŒMySQLåˆå§‹åŒ–è„šæœ¬
mysql -uroot -p780122 < /opt/project/bigdata/mysql/init_mysql.sql

# 4. éªŒè¯è¡¨å·²åˆ›å»º
mysql -uroot -p780122 library_analysis -e "SHOW TABLES;"
```

**é¢„æœŸè¾“å‡ºï¼ˆ29å¼ è¡¨ï¼‰**ï¼š
```
+--------------------------------+
| Tables_in_library_analysis     |
+--------------------------------+
| active_users                   |
| book_association_rules         |
| book_dimension                 |
| book_heat_prediction           |
| book_lend_summary              |
| book_recommend_base            |
| book_recommendations           |
| cluster_summary                |
| collection_utilization_analysis|
| daily_stats                    |
| dept_lend_summary              |
| dept_preference                |
| hot_books                      |
| lend_trend                     |
| lend_trend_prediction          |
| major_reading_profile          |
| operation_dashboard            |
| overdue_analysis               |
| overdue_risk_prediction        |
| recent_lend_records            |
| recommendation_stats           |
| subject_lend_summary           |
| sys_user                       |
| time_distribution              |
| user_clusters                  |
| user_dimension                 |
| user_lend_summary              |
| user_profile                   |
| user_ranking                   |
+--------------------------------+
29 rows in set (0.00 sec)
```

**è¡¨ç»“æ„è¯´æ˜**ï¼š
- **ç»´åº¦è¡¨ï¼ˆ3å¼ ï¼‰**ï¼šuser_dimension, book_dimension, recent_lend_records
- **æ±‡æ€»è¡¨ï¼ˆ5å¼ ï¼‰**ï¼šuser_lend_summary, book_lend_summary, dept_lend_summary, subject_lend_summary, daily_stats
- **èšåˆè¡¨ï¼ˆ5å¼ ï¼‰**ï¼šhot_books, active_users, dept_preference, lend_trend, operation_dashboard
- **åŠŸèƒ½è¡¨ï¼ˆ10å¼ ï¼‰**ï¼šbook_recommendations, recommendation_stats, user_profile, major_reading_profile, overdue_analysis, collection_utilization_analysis, time_distribution, user_ranking, book_recommend_base, sys_user
- **æŒ–æ˜è¡¨ï¼ˆ3å¼ ï¼‰**ï¼šbook_association_rules, user_clusters, cluster_summary
- **é¢„æµ‹è¡¨ï¼ˆ3å¼ ï¼‰**ï¼šoverdue_risk_prediction, lend_trend_prediction, book_heat_prediction

**å¯é€‰ï¼šæµ‹è¯•MySQLè¿æ¥**
```bash
# ä½¿ç”¨æµ‹è¯•è„šæœ¬éªŒè¯è¿æ¥å’Œè¡¨çŠ¶æ€
cd /home/hadoop/library-analysis-system/deploy
bash test_mysql_connection.sh
```

### 1.5 å‡†å¤‡æ•°æ®

```bash
# å°†CSVæ–‡ä»¶æ”¾åˆ°masterèŠ‚ç‚¹
scp LENDHIST2019_2020.csv hadoop@master:/home/hadoop/
```

---

## äºŒã€æ•°æ®é“¾è·¯æ‰§è¡Œ

### 2.1 è„šæœ¬ç»“æ„ï¼ˆå·²ç®€åŒ–ï¼‰

```
deploy/
â”œâ”€â”€ config.sh                 # ç»Ÿä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ run.sh                    # æ•°æ®é“¾è·¯æ‰§è¡Œè„šæœ¬ï¼ˆ9ä¸ªæ­¥éª¤ï¼‰
â”œâ”€â”€ verify.sh                 # æ•°æ®é“¾è·¯éªŒè¯è„šæœ¬
â”œâ”€â”€ clean_old_data.sh         # æ•°æ®æ¸…ç†è„šæœ¬
â””â”€â”€ test_mysql_connection.sh  # MySQLè¿æ¥æµ‹è¯•è„šæœ¬
```

**è¯´æ˜**ï¼š
- `run.sh` - æ•´åˆäº†æ‰€æœ‰9ä¸ªæ­¥éª¤ï¼Œå¯ä¸€é”®æ‰§è¡Œæˆ–åˆ†æ­¥æ‰§è¡Œ
- `verify.sh` - æ•´åˆäº†æ‰€æœ‰éªŒè¯é€»è¾‘ï¼Œå¯éªŒè¯å•æ­¥æˆ–å…¨éƒ¨
- `config.sh` - é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®é¡¹
- `clean_old_data.sh` - æ¸…ç†ä¸­é—´æ•°æ®ï¼Œä¿ç•™HDFSåŸå§‹æ–‡ä»¶
- `test_mysql_connection.sh` - æµ‹è¯•MySQLè¿æ¥å’Œè¡¨çŠ¶æ€

### 2.2 ä¸Šä¼ è„šæœ¬

```bash
# åœ¨Windows/Macä¸Š
cd /path/to/library-analysis-system
scp deploy/*.sh hadoop@master:/home/hadoop/library-analysis-system/deploy/
```

### 2.3 é…ç½®ä¿®æ”¹

```bash
# SSHç™»å½•master
ssh hadoop@master

# è¿›å…¥è„šæœ¬ç›®å½•
cd /home/hadoop/library-analysis-system/deploy

# ä¿®æ”¹é…ç½®ï¼ˆå¦‚éœ€è¦ï¼‰
vim config.sh
```

**å…³é”®é…ç½®é¡¹**ï¼š

```bash
# MySQLå¯†ç 
export MYSQL_PASSWORD="780122"

# MySQL JDBCé©±åŠ¨è·¯å¾„
export MYSQL_JDBC_JAR="/home/hadoop/mysql-connector-java-8.0.33.jar"

# Sparkèµ„æºé…ç½®ï¼ˆæ ¹æ®é›†ç¾¤è°ƒæ•´ï¼‰
export SPARK_EXECUTOR_MEMORY="1500m"
export SPARK_EXECUTOR_CORES="2"
export SPARK_NUM_EXECUTORS="2"
export SPARK_DRIVER_MEMORY="1g"

# æ•°æ®è·¯å¾„
export LOCAL_CSV_FILE="/home/hadoop/LENDHIST2019_2020.csv"
```

### 2.4 æ•°æ®æ ¼å¼æ£€æŸ¥ï¼ˆé‡è¦ï¼‰âš ï¸

åœ¨æ‰§è¡Œæ•°æ®æ¸…æ´—ä¹‹å‰ï¼Œ**å¼ºçƒˆå»ºè®®**å…ˆè¿è¡Œæ•°æ®æ ¼å¼æ£€æŸ¥è„šæœ¬ï¼Œç¡®ä¿CSVæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼š

```bash
# æ£€æŸ¥æœ¬åœ°CSVæ–‡ä»¶æ ¼å¼
chmod +x check_data_format.sh
./check_data_format.sh
```

**æ£€æŸ¥é¡¹ç›®ï¼š**
- âœ… æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
- âœ… æ–‡ä»¶ç¼–ç ï¼ˆUTF-8ï¼‰
- âœ… CSVè¡¨å¤´åˆ—åï¼ˆUSERID, BOOK_ID, LEND_DATEç­‰å¤§å†™å­—æ®µï¼‰
- âœ… åˆ†éš”ç¬¦ï¼ˆå¿…é¡»æ˜¯é€—å·`,`ï¼‰
- âœ… ç©ºå€¼ç»Ÿè®¡ï¼ˆUSERIDã€BOOK_IDã€LEND_DATEï¼‰
- âœ… é¢„ä¼°æœ‰æ•ˆè®°å½•æ•°

**é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š**

```
âœ… æ•°æ®æ ¼å¼æ£€æŸ¥å®Œæˆ

æ€»æ•°æ®è¡Œæ•°: 99255
é¢„è®¡è¿‡æ»¤è®°å½•æ•°: 0
é¢„è®¡æœ‰æ•ˆè®°å½•æ•°: 99255

ğŸ“Œ æç¤º:
1. CSVæ–‡ä»¶ä½¿ç”¨é€—å·(,)ä½œä¸ºåˆ†éš”ç¬¦ - âœ…
2. è¡¨å¤´ä½¿ç”¨å¤§å†™å­—æ¯ï¼ˆUSERID, BOOK_IDç­‰ï¼‰- âœ…
3. æ—¥æœŸæ ¼å¼æ”¯æŒ: 2020-01-1321:23:17 æˆ– 2020-01-13 21:23:17
```

> **æ³¨æ„ï¼š** å¦‚æœæ£€æŸ¥å‘ç°é—®é¢˜ï¼ˆå¦‚ç¼–ç é”™è¯¯ã€åˆ—åä¸åŒ¹é…ã€åˆ†éš”ç¬¦é”™è¯¯ï¼‰ï¼Œè¯·å…ˆä¿®å¤æ•°æ®æ–‡ä»¶ï¼Œå†ç»§ç»­åç»­æ­¥éª¤ã€‚

### 2.5 æ‰§è¡Œæ–¹å¼

#### æ–¹å¼1ï¼šä¸€é”®æ‰§è¡Œï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
chmod +x *.sh
bash run.sh
```

æ‰§è¡Œå…¨éƒ¨9ä¸ªæ­¥éª¤ï¼ˆæ­¥éª¤7-9ä¸ºå¯é€‰ç®—æ³•ï¼‰ï¼Œé¢„è®¡è€—æ—¶ï¼š15-25åˆ†é’Ÿ

#### æ–¹å¼2ï¼šåˆ†æ­¥æ‰§è¡Œï¼ˆæ¨èè°ƒè¯•ï¼‰

```bash
# æ­¥éª¤1: ä¸Šä¼ æ•°æ®åˆ°HDFS (10ç§’)
bash run.sh 1
bash verify.sh 1

# æ­¥éª¤2: åˆ›å»ºHiveè¡¨ (30ç§’)
bash run.sh 2
bash verify.sh 2

# æ­¥éª¤3: æ•°æ®æ¸…æ´— - ODSâ†’DWD (2-5åˆ†é’Ÿ) âš ï¸ æ ¸å¿ƒæ­¥éª¤
bash run.sh 3
bash verify.sh 3

# æ­¥éª¤4: æ•°æ®æ±‡æ€» - DWDâ†’DWS (1-2åˆ†é’Ÿ)
bash run.sh 4
bash verify.sh 4

# æ­¥éª¤5: æ•°æ®åˆ†æ - DWSâ†’ADS (1-2åˆ†é’Ÿ)
bash run.sh 5
bash verify.sh 5

# æ­¥éª¤6: å¯¼å‡ºMySQL - Hiveâ†’MySQL (1-3åˆ†é’Ÿ)
bash run.sh 6
bash verify.sh 6

# æ­¥éª¤7: æ¨èç®—æ³• (3-5åˆ†é’Ÿ)
bash run.sh 7
bash verify.sh 7

# æ­¥éª¤8: é«˜çº§æ•°æ®æŒ–æ˜ - FPGrowth+K-means (2-4åˆ†é’Ÿ)
bash run.sh 8
bash verify.sh 8

# æ­¥éª¤9: é¢„æµ‹æ¨¡å‹ - éšæœºæ£®æ— (2-4åˆ†é’Ÿ)
bash run.sh 9
bash verify.sh 9
```

#### æŸ¥çœ‹å¸®åŠ©

```bash
bash run.sh --help
bash verify.sh --help
```

---

## ä¸‰ã€æ­¥éª¤éªŒè¯

### 3.1 éªŒè¯è„šæœ¬ä½¿ç”¨

```bash
# éªŒè¯å•ä¸ªæ­¥éª¤
bash verify.sh 1  # éªŒè¯æ­¥éª¤1
bash verify.sh 3  # éªŒè¯æ­¥éª¤3

# éªŒè¯æ‰€æœ‰æ­¥éª¤
bash verify.sh
```

### 3.2 å„æ­¥éª¤éªŒè¯æ ‡å‡†

#### æ­¥éª¤1: HDFSä¸Šä¼ 

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 1
```

**é¢„æœŸç»“æœ**ï¼š
```
âœ“ HDFSæ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: 15.2 M
æ–‡ä»¶è¡Œæ•°: 99255
```

**æ‰‹åŠ¨æ£€æŸ¥**ï¼š
```bash
hdfs dfs -ls /data/library/raw/
hdfs dfs -cat /data/library/raw/LENDHIST2019_2020.csv | head -3
```

---

#### æ­¥éª¤2: Hiveå»ºè¡¨

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 2
```

**é¢„æœŸç»“æœ**ï¼š
```
âœ“ Hiveæ•°æ®åº“å·²åˆ›å»º
library_ads
library_dwd
library_dws
library_ods

âœ“ DWDå±‚è¡¨å·²åˆ›å»º
dwd_book_info
dwd_lend_detail
dwd_user_info
```

**æ‰‹åŠ¨æ£€æŸ¥**ï¼š
```bash
hive -e "SHOW DATABASES"
hive -e "USE library_dwd; SHOW TABLES"
```

---

#### æ­¥éª¤3: Sparkæ¸…æ´— âš ï¸

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 3
```

**é¢„æœŸç»“æœ**ï¼š
```
ç”¨æˆ·ç»´åº¦è®°å½•æ•°: 15234
å›¾ä¹¦ç»´åº¦è®°å½•æ•°: 12456
å€Ÿé˜…æ˜ç»†è®°å½•æ•°: 99254
âœ“ Sparkæ•°æ®æ¸…æ´—æˆåŠŸ
```

**å¦‚æœå‡ºç°0æ¡æ•°æ®**ï¼Œè¯·è·³è½¬åˆ° [å…­ã€é—®é¢˜æ’æŸ¥ â†’ 6.1](#61-æ•°æ®æ¸…æ´—å0æ¡è®°å½•)

**æ‰‹åŠ¨æ£€æŸ¥**ï¼š
```bash
hive -e "
SELECT COUNT(*) FROM library_dwd.dwd_user_info WHERE dt='$(date +%Y%m%d)';
SELECT COUNT(*) FROM library_dwd.dwd_book_info WHERE dt='$(date +%Y%m%d)';
SELECT COUNT(*) FROM library_dwd.dwd_lend_detail WHERE dt='$(date +%Y%m%d)';
"
```

---

#### æ­¥éª¤4: Hiveèšåˆ

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 4
```

**é¢„æœŸç»“æœ**ï¼š
```
ç”¨æˆ·ç»Ÿè®¡è®°å½•æ•°: 15234
å›¾ä¹¦ç»Ÿè®¡è®°å½•æ•°: 12456
âœ“ Hiveæ•°æ®èšåˆæˆåŠŸ
```

---

#### æ­¥éª¤5: Sparkåˆ†æ

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 5
```

**é¢„æœŸç»“æœ**ï¼š
```
çƒ­é—¨å›¾ä¹¦è®°å½•æ•°: 50
âœ“ Sparkæ•°æ®åˆ†ææˆåŠŸ

å‰5æ¡çƒ­é—¨å›¾ä¹¦:
+------------------+--------------+
| title            | borrow_count |
+------------------+--------------+
| å›¾ä¹¦A            | 523          |
+------------------+--------------+
```

**æ‰‹åŠ¨æ£€æŸ¥**ï¼š
```bash
mysql -u root -p780122 -h master -D library_analysis -e "
SELECT title, borrow_count FROM hot_books 
ORDER BY borrow_count DESC LIMIT 5;
"
```

---

#### æ­¥éª¤6: å¯¼å‡ºMySQL

**éªŒè¯å‘½ä»¤**ï¼š
```bash
bash verify.sh 6
```

**é¢„æœŸç»“æœ**ï¼š
```
âœ“ MySQLè¡¨å¯¼å‡ºæˆåŠŸï¼ˆ20å¼ è¡¨ï¼‰
```

**æ‰‹åŠ¨æ£€æŸ¥**ï¼š
```bash
mysql -u root -p780122 -h master -D library_analysis -e "
SELECT table_name, table_rows FROM information_schema.tables 
WHERE table_schema='library_analysis';
"
```

---

### 3.3 æœ€ç»ˆéªŒè¯

```bash
# éªŒè¯æ‰€æœ‰æ­¥éª¤
bash verify.sh

# æŸ¥çœ‹MySQLæœ€ç»ˆç»“æœ
mysql -u root -p780122 -h master -D library_analysis -e "
SELECT 'æ¨èæ•°æ®' as è¡¨å, COUNT(*) as è®°å½•æ•° FROM book_recommendations
UNION ALL
SELECT 'çƒ­é—¨å›¾ä¹¦', COUNT(*) FROM hot_books;
"
```

**æˆåŠŸæ ‡å¿—**ï¼š
```
+-----------+----------+
| è¡¨å       | è®°å½•æ•°   |
+-----------+----------+
| æ¨èæ•°æ®   | 50000    |
| çƒ­é—¨å›¾ä¹¦   | 50       |
+-----------+----------+
```

---

## å››ã€åç«¯éƒ¨ç½²

### 4.1 ä¿®æ”¹é…ç½®

```bash
cd backend/src/main/resources

# ä¿®æ”¹application.yml
vim application.yml
```

**å…³é”®é…ç½®**ï¼š
```yaml
spring:
  datasource:
    url: jdbc:mysql://master:3306/library_analysis
    username: root
    password: 780122

server:
  port: 8080
```

### 4.2 æ‰“åŒ…éƒ¨ç½²

```bash
cd backend

# æ‰“åŒ…
mvn clean package -DskipTests

# è¿è¡Œ
java -jar target/library-analysis-0.0.1-SNAPSHOT.jar

# æˆ–åå°è¿è¡Œ
nohup java -jar target/library-analysis-0.0.1-SNAPSHOT.jar > app.log 2>&1 &
```

### 4.3 éªŒè¯åç«¯

```bash
# æ£€æŸ¥æœåŠ¡
curl http://localhost:8080/api/health

# æŸ¥çœ‹æ—¥å¿—
tail -f app.log
```

---

## äº”ã€å‰ç«¯éƒ¨ç½²

### 5.1 ä¿®æ”¹é…ç½®

```bash
cd frontend

# ä¿®æ”¹APIåœ°å€
vim .env.development
```

```
VITE_API_BASE_URL=http://master:8080/api
```

### 5.2 æœ¬åœ°å¼€å‘æ¨¡å¼

```bash
npm install
npm run dev
```

è®¿é—®: http://localhost:3000

### 5.3 ç”Ÿäº§éƒ¨ç½²

```bash
# æ„å»º
npm run build

# éƒ¨ç½²åˆ°Nginx
cp -r dist/* /usr/share/nginx/html/
```

---
## å…­ã€é—®é¢˜æ’æŸ¥

### 6.1 æ•°æ®æ¸…æ´—å0æ¡è®°å½•

**ç°è±¡**ï¼š
```
æ¸…æ´—åè®°å½•æ•°: 0
ç”¨æˆ·ç»´åº¦è®°å½•æ•°: 0
å›¾ä¹¦ç»´åº¦è®°å½•æ•°: 0
```

**åŸå› **ï¼šCSVåˆ†éš”ç¬¦ä¸åŒ¹é…

**æ’æŸ¥æ­¥éª¤**ï¼š

1. **æŸ¥çœ‹CSVæ–‡ä»¶å®é™…æ ¼å¼**ï¼š
```bash
hdfs dfs -cat /data/library/raw/LENDHIST2019_2020.csv | head -3
```

2. **åˆ¤æ–­åˆ†éš”ç¬¦**ï¼š
   - Tabåˆ†éš”ï¼ˆ`\t`ï¼‰ï¼šå­—æ®µä¹‹é—´æœ‰æ˜æ˜¾ç©ºç™½
   - é€—å·åˆ†éš”ï¼ˆ`,`ï¼‰ï¼šå­—æ®µä¹‹é—´æ˜¯é€—å·

3. **ä¿®æ”¹Pythonè„šæœ¬**ï¼š
```bash
vim /home/hadoop/library-analysis-system/bigdata/spark/data_clean.py

# æ‰¾åˆ°ç¬¬59è¡Œ
# Tabåˆ†éš”ï¼š
.option("delimiter", "\t")

# é€—å·åˆ†éš”ï¼š
.option("delimiter", ",")
```

4. **é‡æ–°è¿è¡Œ**ï¼š
```bash
bash run.sh 3
bash verify.sh 3
```

---

### 6.2 MySQL JDBCé©±åŠ¨ä¸å­˜åœ¨

**é”™è¯¯ä¿¡æ¯**ï¼š
```
File file:/opt/app/spark/jars/mysql-connector-java-8.0.33.jar does not exist
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ‰‹åŠ¨ä¸‹è½½åˆ°config.shé…ç½®çš„è·¯å¾„
cd /home/hadoop
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar

# éªŒè¯
ls -lh mysql-connector-java-8.0.33.jar
```

---

### 6.3 Yarnèµ„æºä¸è¶³

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Requested more than the maximum memory capability of the cluster
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

ä¿®æ”¹ `config.sh` é™ä½èµ„æºé…ç½®ï¼š

```bash
vim config.sh

# ä¿®æ”¹ä¸ºï¼š
export SPARK_EXECUTOR_MEMORY="1g"    # ä»1500mé™ä½
export SPARK_NUM_EXECUTORS="1"       # ä»2é™ä½åˆ°1
export SPARK_DRIVER_MEMORY="512m"    # ä»1gé™ä½
```

---

### 6.4 Hive Metastoreè¿æ¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
Could not connect to meta store using any of the URIs provided
```

**æ£€æŸ¥**ï¼š
```bash
# æ£€æŸ¥MetastoreæœåŠ¡
jps | grep HiveMetaStore

# å¦‚æœæ²¡æœ‰ï¼Œå¯åŠ¨å®ƒ
hive --service metastore &

# æ£€æŸ¥MySQLè¿æ¥
mysql -u root -p780122 -e "USE hive_metastore; SHOW TABLES"
```

---

### 6.5 Pythonä¾èµ–ç¼ºå¤±

**é”™è¯¯ä¿¡æ¯**ï¼š
```
ModuleNotFoundError: No module named 'pandas'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
pip3 install --user pandas pymysql
```

---

### 6.6 MySQLè¡¨æœªåˆ›å»º

**ç°è±¡**ï¼š
```bash
# æ‰§è¡Œæ­¥éª¤6å¯¼å‡ºMySQLæ—¶æŠ¥é”™
ERROR 1146 (42S02): Table 'library_analysis.user_dimension' doesn't exist
```

**åŸå› **ï¼šæœªæ‰§è¡ŒMySQLåˆå§‹åŒ–è„šæœ¬

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
mysql -uroot -p780122 library_analysis -e "SHOW TABLES;"

# 2. å¦‚æœè¡¨ä¸å­˜åœ¨ï¼Œæ‰§è¡Œåˆå§‹åŒ–è„šæœ¬
 mysql -uroot -p780122 < /opt/project/library-analysis-system/bigdata/mysql/init_mysql.sql

# 3. éªŒè¯29å¼ è¡¨å·²åˆ›å»º
bash test_mysql_connection.sh
```

---

### 6.7 MySQLè¿æ¥å¤±è´¥

**ç°è±¡**ï¼š
```bash
# clean_old_data.shæ¸…ç†æ—¶æŠ¥é”™
âŒ MySQLè¿æ¥å¤±è´¥ï¼
   ä¸»æœº: master
   ç”¨æˆ·: root
```

**æ’æŸ¥æ­¥éª¤**ï¼š

1. **æ£€æŸ¥MySQLæœåŠ¡**ï¼š
```bash
systemctl status mysqld
# å¦‚æœæœªå¯åŠ¨
systemctl start mysqld
```

2. **æµ‹è¯•è¿æ¥**ï¼š
```bash
mysql -uroot -p780122 -hmaster -e "SELECT 1;"

# æˆ–ä½¿ç”¨æµ‹è¯•è„šæœ¬
bash test_mysql_connection.sh
```

3. **æ£€æŸ¥é˜²ç«å¢™**ï¼š
```bash
firewall-cmd --list-ports
firewall-cmd --add-port=3306/tcp --permanent
firewall-cmd --reload
```

4. **æ£€æŸ¥MySQLé…ç½®**ï¼š
```bash
# ç¡®ä¿MySQLå…è®¸è¿œç¨‹è¿æ¥
vim /etc/my.cnf

# æ£€æŸ¥bind-addressï¼ˆåº”è¯¥æ˜¯0.0.0.0æˆ–æ³¨é‡Šæ‰ï¼‰
# bind-address = 0.0.0.0
```

---

### 6.8 æ¸…ç†è„šæœ¬æ— æ³•æ¸…ç©ºMySQLè¡¨

**ç°è±¡**ï¼š
```bash
bash clean_old_data.sh
# MySQLè¡¨æ•°æ®ä»ç„¶å­˜åœ¨
```

**åŸå› **ï¼šä¹‹å‰ç‰ˆæœ¬çš„è„šæœ¬ä½¿ç”¨äº†é”™è¯¯çš„SQLè¯­æ³• `TRUNCATE TABLE IF EXISTS`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. ç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„clean_old_data.sh
git pull origin main

# 2. æ‰‹åŠ¨æ¸…ç©ºæ‰€æœ‰è¡¨ï¼ˆå¦‚æœè„šæœ¬å¤±è´¥ï¼‰
mysql -uroot -p780122 library_analysis << EOF
TRUNCATE TABLE user_dimension;
TRUNCATE TABLE book_dimension;
TRUNCATE TABLE recent_lend_records;
TRUNCATE TABLE user_lend_summary;
TRUNCATE TABLE book_lend_summary;
TRUNCATE TABLE dept_lend_summary;
TRUNCATE TABLE subject_lend_summary;
TRUNCATE TABLE daily_stats;
TRUNCATE TABLE hot_books;
TRUNCATE TABLE active_users;
TRUNCATE TABLE dept_preference;
TRUNCATE TABLE lend_trend;
TRUNCATE TABLE operation_dashboard;
TRUNCATE TABLE book_recommendations;
EOF

# 3. ä½¿ç”¨æ”¹è¿›çš„æ¸…ç†è„šæœ¬
bash clean_old_data.sh
```

**éªŒè¯æ¸…ç†æˆåŠŸ**ï¼š
```bash
# æ‰€æœ‰è¡¨çš„è¡Œæ•°åº”è¯¥ä¸º0
mysql -uroot -p780122 library_analysis -e "
SELECT table_name, table_rows 
FROM information_schema.tables 
WHERE table_schema='library_analysis';
"
```

---

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–

### 7.1 Sparkä¼˜åŒ–

ä¿®æ”¹ `config.sh`ï¼š

```bash
# å¢åŠ å¹¶è¡Œåº¦
export SPARK_SHUFFLE_PARTITIONS="40"  # é»˜è®¤20

# å¢åŠ Executorèµ„æºï¼ˆå¦‚æœé›†ç¾¤å…è®¸ï¼‰
export SPARK_EXECUTOR_MEMORY="2g"
export SPARK_NUM_EXECUTORS="3"
```

### 7.2 Hiveä¼˜åŒ–

```sql
-- å¼€å¯åŠ¨æ€åˆ†åŒº
SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode=nonstrict;

-- å¼€å¯å‹ç¼©
SET hive.exec.compress.output=true;
SET mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;
```

### 7.3 MySQLä¼˜åŒ–

```sql
-- æ·»åŠ ç´¢å¼•
ALTER TABLE book_recommendations ADD INDEX idx_user_id (user_id);
ALTER TABLE hot_books ADD INDEX idx_borrow_count (borrow_count DESC);
```

---

## å…«ã€è¿ç»´ç›‘æ§

### 8.1 æ—¥å¿—æŸ¥çœ‹

```bash
# Hadoopæ—¥å¿—
tail -f /opt/app/hadoop/logs/hadoop-*.log

# Yarnæ—¥å¿—
yarn logs -applicationId <application_id>

# Hiveæ—¥å¿—
tail -f /opt/app/hive/logs/hive.log

# Sparkæ—¥å¿—
tail -f /opt/app/spark/logs/spark-*.out

# åç«¯æ—¥å¿—
tail -f app.log
```

### 8.2 é›†ç¾¤ç›‘æ§

- **Yarn WebUI**: http://master:8088
- **HDFS WebUI**: http://master:9870
- **Spark History**: http://master:18080

### 8.3 å®šæ—¶è°ƒåº¦

ä½¿ç”¨Cronå®šæ—¶æ‰§è¡Œï¼š

```bash
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
0 2 * * * cd /home/hadoop/library-analysis-system/deploy && bash run.sh >> /home/hadoop/pipeline.log 2>&1
```

---

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### å¸¸ç”¨å‘½ä»¤

```bash
# éªŒè¯æ‰€æœ‰æ­¥éª¤
bash verify.sh

# é‡æ–°è¿è¡ŒæŸä¸€æ­¥
bash run.sh 3

# æŸ¥çœ‹é…ç½®
cat config.sh

# ä¸€é”®æ‰§è¡Œå…¨éƒ¨
bash run.sh

# æŸ¥çœ‹å¸®åŠ©
bash run.sh --help
bash verify.sh --help
```

### é¢„è®¡è€—æ—¶ï¼ˆ10ä¸‡æ¡æ•°æ®ï¼‰

| æ­¥éª¤ | åç§° | è€—æ—¶ |
|-----|------|------|
| æ­¥éª¤1 | ä¸Šä¼ HDFS | 10ç§’ |
| æ­¥éª¤2 | åˆ›å»ºHiveè¡¨ | 30ç§’ |
| æ­¥éª¤3 | æ•°æ®æ¸…æ´—ï¼ˆODSâ†’DWDï¼‰ | 2-5åˆ†é’Ÿ |
| æ­¥éª¤4 | æ•°æ®æ±‡æ€»ï¼ˆDWDâ†’DWSï¼‰ | 1-2åˆ†é’Ÿ |
| æ­¥éª¤5 | æ•°æ®åˆ†æï¼ˆDWSâ†’ADSï¼‰ | 1-2åˆ†é’Ÿ |
| æ­¥éª¤6 | å¯¼å‡ºMySQLï¼ˆ20å¼ è¡¨ï¼‰ | 1-3åˆ†é’Ÿ |
| æ­¥éª¤7 | æ¨èç®—æ³•ï¼ˆå¯é€‰ï¼‰ | 3-5åˆ†é’Ÿ |
| æ­¥éª¤8 | é«˜çº§æŒ–æ˜ï¼ˆå¯é€‰ï¼‰ | 2-4åˆ†é’Ÿ |
| æ­¥éª¤9 | é¢„æµ‹æ¨¡å‹ï¼ˆå¯é€‰ï¼‰ | 2-4åˆ†é’Ÿ |
| **æ€»è®¡** | **å®Œæ•´æµç¨‹** | **15-25åˆ†é’Ÿ** |

---

**å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·æŸ¥çœ‹é¡¹ç›®READMEæˆ–æäº¤Issueã€‚**
