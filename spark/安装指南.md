# ğŸš€ Sparkç¯å¢ƒå®‰è£…æŒ‡å—

## ğŸ“‹ ä¾èµ–æ¸…å•

### Pythonä¾èµ–

è¿è¡ŒSparkè„šæœ¬éœ€è¦ä»¥ä¸‹PythonåŒ…ï¼š

| åŒ…å | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| **pyspark** | 3.5.6 | Sparkæ ¸å¿ƒæ¡†æ¶ |
| **py4j** | 0.10.9.7 | PySparkä¸JVMé€šä¿¡ |
| **pandas** | æœ€æ–° | æ•°æ®å¤„ç†ï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°è°ƒè¯•ï¼‰ |
| **pymysql** | æœ€æ–° | MySQLè¿æ¥ï¼ˆè™½ç„¶å£°æ˜äº†ï¼Œä½†å®é™…ç”¨JDBCï¼‰ |

---

## âœ… ä½ çš„å‘½ä»¤æ˜¯å¯¹çš„ï¼

```bash
pip3 install pyspark==3.5.6 py4j==0.10.9.7 pandas pymysql \
  --no-cache-dir \
  -i https://mirrors.aliyun.com/pypi/simple/
```

### å‘½ä»¤è§£æ

- âœ… **pyspark==3.5.6** - æ­£ç¡®çš„ç‰ˆæœ¬
- âœ… **py4j==0.10.9.7** - ä¸PySpark 3.5.6é…å¥—
- âœ… **pandas** - æ•°æ®å¤„ç†åº“
- âœ… **pymysql** - Python MySQLé©±åŠ¨
- âœ… **--no-cache-dir** - ä¸ç¼“å­˜ï¼ŒèŠ‚çœç©ºé—´
- âœ… **-i https://mirrors.aliyun.com/pypi/simple/** - ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒåŠ é€Ÿ

---

## ğŸ“¦ å®Œæ•´å®‰è£…æ­¥éª¤

### æ–¹å¼1ï¼šä½¿ç”¨requirements.txtï¼ˆæ¨èï¼‰

```bash
cd bigdata/spark
pip3 install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/
```

### æ–¹å¼2ï¼šç›´æ¥å®‰è£…

```bash
pip3 install pyspark==3.5.6 py4j==0.10.9.7 pandas pymysql \
  --no-cache-dir \
  -i https://mirrors.aliyun.com/pypi/simple/
```

### æ–¹å¼3ï¼šæŒ‡å®šæ›´å¤šé•œåƒæºï¼ˆå¤‡é€‰ï¼‰

```bash
# æ¸…åé•œåƒ
pip3 install pyspark==3.5.6 py4j==0.10.9.7 pandas pymysql \
  -i https://pypi.tuna.tsinghua.edu.cn/simple/

# è±†ç“£é•œåƒ
pip3 install pyspark==3.5.6 py4j==0.10.9.7 pandas pymysql \
  -i https://pypi.douban.com/simple/
```

---

## âš ï¸ é‡è¦ï¼šMySQL JDBCé©±åŠ¨

### Pythonä¾èµ– vs JDBCé©±åŠ¨

| ç»„ä»¶ | ç”¨é€” | æ˜¯å¦éœ€è¦ |
|------|------|----------|
| **pymysql** | Pythonç›´æ¥è¿æ¥MySQL | âŒ è„šæœ¬ä¸­æœªä½¿ç”¨ |
| **MySQL JDBCé©±åŠ¨** | Sparké€šè¿‡JDBCè¿æ¥MySQL | âœ… **å¿…éœ€ï¼** |

### ä¸ºä»€ä¹ˆéœ€è¦JDBCé©±åŠ¨ï¼Ÿ

Sparkä½¿ç”¨JDBCè¿æ¥MySQLï¼Œéœ€è¦MySQL Connector/Jï¼š

```python
# 04_data_export.py ä¸­çš„ä»£ç 
df.write.mode("overwrite").jdbc(
    url="jdbc:mysql://master:3306/library_analysis",
    table="user_dimension",
    properties={
        "driver": "com.mysql.cj.jdbc.Driver"  # â† éœ€è¦JDBCé©±åŠ¨ï¼
    }
)
```

### ä¸‹è½½MySQL JDBCé©±åŠ¨

```bash
# ä¸‹è½½MySQL Connector/J 8.0.33
cd $SPARK_HOME/jars
wget https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar

# æˆ–ä½¿ç”¨å›½å†…é•œåƒ
wget https://maven.aliyun.com/repository/public/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar
```

### é…ç½®æ–¹å¼

#### æ–¹å¼1ï¼šå¤åˆ¶åˆ°Spark jarsç›®å½•ï¼ˆæ¨èï¼‰

```bash
cp mysql-connector-j-8.0.33.jar $SPARK_HOME/jars/
```

#### æ–¹å¼2ï¼šè¿è¡Œæ—¶æŒ‡å®š

```bash
spark-submit \
  --jars /path/to/mysql-connector-j-8.0.33.jar \
  your_script.py
```

#### æ–¹å¼3ï¼šåœ¨ä»£ç ä¸­é…ç½®

```python
spark = SparkSession.builder \
    .config("spark.jars", "/path/to/mysql-connector-j-8.0.33.jar") \
    .getOrCreate()
```

---

## ğŸ”§ ç³»ç»Ÿä¾èµ–

### Javaç¯å¢ƒ

PySparkéœ€è¦Java 8æˆ–Java 11ï¼š

```bash
# æ£€æŸ¥Javaç‰ˆæœ¬
java -version

# åº”è¯¥æ˜¾ç¤ºç±»ä¼¼ï¼š
# openjdk version "1.8.0_xxx" æˆ– "11.0.xx"
```

å¦‚æœæ²¡æœ‰Javaï¼š

```bash
# CentOS/RHEL
sudo yum install java-1.8.0-openjdk-devel

# Ubuntu/Debian
sudo apt install openjdk-8-jdk

# è®¾ç½®JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

### Hadoopï¼ˆå¦‚æœä½¿ç”¨HDFSï¼‰

å¦‚æœè¯»å–HDFSæ•°æ®ï¼Œéœ€è¦é…ç½®Hadoopç¯å¢ƒå˜é‡ï¼š

```bash
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export PATH=$HADOOP_HOME/bin:$PATH
```

### Hiveï¼ˆå¦‚æœä½¿ç”¨Hiveï¼‰

è„šæœ¬ä¸­ä½¿ç”¨äº†Hiveæ”¯æŒï¼š

```python
spark = SparkSession.builder \
    .enableHiveSupport() \  # â† éœ€è¦Hive
    .getOrCreate()
```

ç¡®ä¿é…ç½®äº†Hiveï¼š

```bash
export HIVE_HOME=/usr/local/hive
export HIVE_CONF_DIR=$HIVE_HOME/conf
```

---

## ğŸ§ª éªŒè¯å®‰è£…

### 1. éªŒè¯Pythonä¾èµ–

```bash
python3 -c "import pyspark; print(pyspark.__version__)"
# è¾“å‡º: 3.5.6

python3 -c "import py4j; print(py4j.__version__)"
# è¾“å‡º: 0.10.9.7

python3 -c "import pandas; print(pandas.__version__)"
# è¾“å‡º: 2.x.x

python3 -c "import pymysql; print(pymysql.__version__)"
# è¾“å‡º: 1.x.x
```

### 2. éªŒè¯PySparkç¯å¢ƒ

```bash
pyspark --version
# åº”è¯¥æ˜¾ç¤º: Welcome to ... Spark 3.5.6
```

### 3. æµ‹è¯•Sparkä¼šè¯

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Test") \
    .getOrCreate()

print(f"Spark Version: {spark.version}")
print(f"Spark Master: {spark.sparkContext.master}")

spark.stop()
```

### 4. éªŒè¯JDBCé©±åŠ¨

```bash
# æ£€æŸ¥MySQL JDBCé©±åŠ¨æ˜¯å¦å­˜åœ¨
ls -lh $SPARK_HOME/jars/mysql-connector-j*.jar

# æˆ–åœ¨Pythonä¸­æµ‹è¯•
python3 << EOF
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()
try:
    # å°è¯•åŠ è½½MySQLé©±åŠ¨
    spark._jvm.Class.forName("com.mysql.cj.jdbc.Driver")
    print("âœ… MySQL JDBCé©±åŠ¨å·²å®‰è£…")
except:
    print("âŒ MySQL JDBCé©±åŠ¨æœªæ‰¾åˆ°")
spark.stop()
EOF
```

---

## ğŸ“‚ è„šæœ¬è¯´æ˜

### é¡¹ç›®ä¸­çš„Sparkè„šæœ¬

| è„šæœ¬ | åŠŸèƒ½ | ä¾èµ– |
|------|------|------|
| **01_data_clean.py** | æ•°æ®æ¸…æ´—ï¼ˆHDFSâ†’Hiveï¼‰ | PySpark + Hive |
| **02_data_aggregate.py** | æ•°æ®æ±‡æ€»ï¼ˆDWDâ†’DWSï¼‰ | PySpark + Hive |
| **03_data_analyze.py** | æ•°æ®åˆ†æï¼ˆDWSâ†’ADSï¼‰ | PySpark + Hive |
| **04_data_export.py** | æ•°æ®å¯¼å‡ºï¼ˆHiveâ†’MySQLï¼‰ | PySpark + JDBC |
| **05_book_recommend.py** | å›¾ä¹¦æ¨èç³»ç»Ÿ | PySpark + Hive + JDBC |

### è¿è¡Œè„šæœ¬ç¤ºä¾‹

```bash
# è®¾ç½®Pythonè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
export PYSPARK_PYTHON=python3

# è¿è¡Œæ•°æ®æ¸…æ´—
python3 01_data_clean.py

# è¿è¡Œæ•°æ®æ±‡æ€»
python3 02_data_aggregate.py

# è¿è¡Œæ•°æ®åˆ†æ
python3 03_data_analyze.py

# è¿è¡Œæ•°æ®å¯¼å‡ºï¼ˆéœ€è¦MySQL JDBCé©±åŠ¨ï¼‰
python3 04_data_export.py

# è¿è¡Œæ¨èç³»ç»Ÿ
python3 05_book_recommend.py
```

---

## ğŸ› å¸¸è§é—®é¢˜

### 1. æ‰¾ä¸åˆ°Java

```
Error: JAVA_HOME is not set
```

**è§£å†³ï¼š**
```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

### 2. PySparkç‰ˆæœ¬ä¸åŒ¹é…

```
Py4JError: py4j.protocol.Py4JError
```

**è§£å†³ï¼š** ç¡®ä¿py4jç‰ˆæœ¬ä¸PySparkåŒ¹é…
```bash
pip3 uninstall pyspark py4j
pip3 install pyspark==3.5.6 py4j==0.10.9.7
```

### 3. MySQL JDBCé©±åŠ¨æœªæ‰¾åˆ°

```
java.sql.SQLException: No suitable driver found for jdbc:mysql://
```

**è§£å†³ï¼š** ä¸‹è½½å¹¶å®‰è£…MySQL JDBCé©±åŠ¨ï¼ˆè§ä¸Šæ–‡ï¼‰

### 4. Hive Metastoreè¿æ¥å¤±è´¥

```
MetaException: Could not connect to meta store
```

**è§£å†³ï¼š**
- æ£€æŸ¥Hive MetastoreæœåŠ¡æ˜¯å¦å¯åŠ¨
- æ£€æŸ¥hive-site.xmlé…ç½®
- ç¡®è®¤thrift://master:9083å¯è®¿é—®

### 5. å†…å­˜ä¸è¶³

```
java.lang.OutOfMemoryError: Java heap space
```

**è§£å†³ï¼š** å¢åŠ Sparkå†…å­˜
```bash
export SPARK_DRIVER_MEMORY=4g
export SPARK_EXECUTOR_MEMORY=4g

# æˆ–åœ¨ä»£ç ä¸­
spark = SparkSession.builder \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()
```

---

## ğŸ“Œ æœ€ä½³å®è·µ

### 1. è™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv spark-env
source spark-env/bin/activate

# å®‰è£…ä¾èµ–
pip3 install -r requirements.txt

# è¿è¡Œè„šæœ¬
python3 01_data_clean.py

# é€€å‡ºè™šæ‹Ÿç¯å¢ƒ
deactivate
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# Java
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

# Spark
export SPARK_HOME=/usr/local/spark
export PATH=$SPARK_HOME/bin:$PATH
export PYSPARK_PYTHON=python3

# Hadoop (å¦‚æœéœ€è¦)
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

# Hive
export HIVE_HOME=/usr/local/hive
export HIVE_CONF_DIR=$HIVE_HOME/conf

# MySQLè¿æ¥é…ç½®
export MYSQL_HOST=master
export MYSQL_PORT=3306
export MYSQL_USER=root
export MYSQL_PASSWORD=780122
export MYSQL_DATABASE=library_analysis
```

åŠ è½½ç¯å¢ƒå˜é‡ï¼š
```bash
source .env
```

### 3. æ‰¹é‡è¿è¡Œè„šæœ¬

åˆ›å»º `run_all.sh`ï¼š

```bash
#!/bin/bash
set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹è¿è¡ŒSparkæ•°æ®å¤„ç†æµç¨‹"

echo "ğŸ“Œ [1/5] æ•°æ®æ¸…æ´—..."
python3 01_data_clean.py

echo "ğŸ“Œ [2/5] æ•°æ®æ±‡æ€»..."
python3 02_data_aggregate.py

echo "ğŸ“Œ [3/5] æ•°æ®åˆ†æ..."
python3 03_data_analyze.py

echo "ğŸ“Œ [4/5] æ•°æ®å¯¼å‡º..."
python3 04_data_export.py

echo "ğŸ“Œ [5/5] å›¾ä¹¦æ¨è..."
python3 05_book_recommend.py

echo "âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼"
```

è¿è¡Œï¼š
```bash
chmod +x run_all.sh
./run_all.sh
```

---

## ğŸ“ æ€»ç»“

### æœ€å°ä¾èµ–æ¸…å•

âœ… **å¿…éœ€ï¼š**
1. Python 3.7+
2. Java 8 æˆ– 11
3. PySpark 3.5.6
4. py4j 0.10.9.7
5. MySQL JDBCé©±åŠ¨ï¼ˆmysql-connector-j-8.0.33.jarï¼‰

âœ… **æ¨èï¼š**
1. pandasï¼ˆæ•°æ®å¤„ç†ï¼‰
2. pymysqlï¼ˆè™½ç„¶æœªç›´æ¥ä½¿ç”¨ï¼Œä½†å£°æ˜äº†ä¾èµ–ï¼‰

âœ… **ç¯å¢ƒï¼š**
1. Hadoopï¼ˆå¦‚æœè¯»å–HDFSï¼‰
2. Hiveï¼ˆå¯ç”¨HiveSupportï¼‰
3. MySQLï¼ˆæ•°æ®å¯¼å‡ºç›®æ ‡ï¼‰

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…Pythonä¾èµ–
pip3 install pyspark==3.5.6 py4j==0.10.9.7 pandas pymysql \
  -i https://mirrors.aliyun.com/pypi/simple/

# 2. ä¸‹è½½MySQL JDBCé©±åŠ¨
wget https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar
cp mysql-connector-j-8.0.33.jar $SPARK_HOME/jars/

# 3. éªŒè¯å®‰è£…
python3 -c "import pyspark; print(pyspark.__version__)"

# 4. è¿è¡Œè„šæœ¬
python3 03_data_analyze.py
```

---

**ä½ çš„å®‰è£…å‘½ä»¤å®Œå…¨æ­£ç¡®ï¼è®°å¾—å®‰è£…MySQL JDBCé©±åŠ¨å°±å¯ä»¥äº†ï¼** ğŸ‰
